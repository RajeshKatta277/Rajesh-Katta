<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Rajesh Katta | AI Engineer</title>
  <style>
    :root {
      --bg: #0b0d10;
      --panel: #12151b;
      --border: #1f2430;
      --text: #eaeaea;
      --muted: #b5b5b5;
      --accent: #7dd3fc;
    }
    body { margin:0; font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif; background:radial-gradient(1200px 600px at 10% -10%, #101522, var(--bg)); color:var(--text); line-height:1.7; }
    a { color:var(--accent); text-decoration:none; }
    .container { max-width:1150px; margin:auto; padding:70px 24px; }
    section { margin-top:110px; }
    h1 { font-size:54px; margin:0 0 10px; }
    h2 { font-size:34px; margin-bottom:20px; }
    h3 { margin-top:0; }
    .muted { color:var(--muted); }
    .grid { display:grid; grid-template-columns:repeat(auto-fit,minmax(300px,1fr)); gap:28px; }
    .card { background:var(--panel); border:1px solid var(--border); border-radius:18px; padding:26px; }
    .badge { display:inline-block; font-size:12px; padding:4px 10px; border-radius:999px; border:1px solid var(--border); color:var(--muted); margin:4px 6px 0 0; }

    .hero { display:grid; grid-template-columns:1.2fr 0.8fr; gap:40px; align-items:center; }
    .hero-card { background:linear-gradient(180deg,#151a25,var(--panel)); border:1px solid var(--border); border-radius:20px; padding:28px; }
    .avatar { width:300px; height:300px; border-radius:80%; border:3px solid var(--border); object-fit:cover; margin-bottom:20px; }
    .links a { display:inline-block; margin:6px 10px 6px 0; padding:8px 14px; border:1px solid var(--border); border-radius:999px; font-size:14px; }

    .timeline { border-left:2px solid var(--border); padding-left:26px; }
    .timeline-item { margin-bottom:44px; position:relative; }
    .timeline-item::before { content:""; position:absolute; left:-36px; top:6px; width:14px; height:14px; background:var(--accent); border-radius:50%; }

    form input, form textarea { width:100%; padding:12px 14px; background:#0f1320; border:1px solid var(--border); border-radius:10px; color:var(--text); margin-bottom:14px; }
    form button { padding:12px 20px; border-radius:999px; border:none; background:var(--accent); color:#000; font-weight:600; cursor:pointer; }

    footer { margin-top:140px; text-align:center; color:#888; font-size:14px; }
    @media(max-width:900px){ .hero{grid-template-columns:1fr;} h1{font-size:44px;} }
  </style>
</head>
<body>
<div class="container">

<section class="hero">
  <div>
    <h1>Rajesh Katta</h1>
    <p class="muted">AI Engineer · Generative AI · LLMs · Computer Vision · Multimodal Systems . Agentic AI</p>
    <p>
      AI Engineer with <strong>2+ years of hands-on experience(3 years including high-impact internships)</strong> in building, fine-tuning, and deploying
      large-scale <strong>Generative AI, LLM, and Multimodal systems</strong>. My work spans end-to-end model development —
      from first-principles implementations to production-grade pipelines serving real-world use cases.
    </p>
    <p>
      I specialize in <strong>LLM fine-tuning (LoRA / PEFT)</strong>, <strong>Retrieval-Augmented Generation (RAG)</strong>,
      <strong>Agentic AI systems</strong>, and <strong>vision–language models</strong>. I enjoy working at the intersection of
      research and engineering — translating cutting-edge ideas into scalable, reliable AI products.
    </p>
    <div class="links">
      <a href="mailto:kattarajesh2001@gmail.com?subject=Portfolio%20Contact&body=Hi%20Rajesh,">
      Gmail
    </a>
      <a href="tel:+918309009504">Phone</a>
      <a href="https://github.com/RajeshKatta277">GitHub</a>
      <a href="https://www.linkedin.com/in/rajesh-katta-42b3741b1">LinkedIn</a>
      <a href="https://medium.com/@kattarajesh2001">Medium</a>
      <a href="Katta_Rajesh_Resume_04022026.pdf" download>Download Resume</a>
    </div>
  </div>
  <div class="hero-card">
    <img src="1759690058467.jpeg" class="avatar" />
    <p><strong>Current:</strong> AI/ML Engineer @ Vassar Labs</p>
    <p><strong>Expertise:</strong> ML, DL ,NLP, GenAI, LLMs, CV, Agentic AI, Multimodal AI</p>
    <p><strong>Mindset:</strong> Research depth → production impact</p>
    
   
  </div>
  
 
</section>

<section>
  <h2>Core Expertise</h2>
  <div class="grid">

    <div class="card">
      <h3>Machine Learning & Deep Learning</h3>
      <ul>
        <li>End-to-end development of machine learning and deep learning models across supervised, unsupervised, and multitask settings.</li>
        <li>Strong foundation in optimization techniques, loss functions, regularization, and training stability.</li>
        <li>Hands-on experience implementing models from scratch and scaling training pipelines for production.</li>
        <li>Designed and trained CNNs, Transformers, Vision Transformers (ViT), and custom neural architectures.</li>
      </ul>
      <p><strong>Core Skills:</strong></p>
      <span class="badge">Machine Learning</span>
      <span class="badge">Deep Learning</span>
      <span class="badge">CNNs</span>
      <span class="badge">Transformers</span>
      <span class="badge">Vision Transformers</span>
      <span class="badge">Optimization</span>
    </div>

    <div class="card">
      <h3>Computer Vision</h3>
      <ul>
        <li>Built and deployed object detection, semantic segmentation, and instance segmentation systems.</li>
        <li>Worked extensively on satellite imagery, agricultural datasets, and real-world vision problems.</li>
        <li>Designed detection pipelines using both one-stage and two-stage architectures.</li>
        <li>Implemented segmentation workflows for buildings, crops, pests, and canopies.</li>
        <li>Hands-on experience with prompt-based and box-guided segmentation using SAM and SAM2.</li>
      </ul>
      <p><strong>Models:</strong></p>
      <span class="badge">Faster R-CNN</span>
      <span class="badge">YOLOv5–v8</span>
      <span class="badge">RetinaNet</span>
      <span class="badge">U-Net</span>
      <span class="badge">U-Net++</span>
      <span class="badge">DeepLabV3+</span>
      <span class="badge">SAM</span>
      <span class="badge">SAM2</span>
    </div>

    <div class="card">
      <h3>LLMs & Generative AI</h3>
      <ul>
        <li>Hands-on experience building and deploying production-grade LLM and GenAI systems.</li>
        <li>Fine-tuned large language models using LoRA and PEFT for domain-specific tasks.</li>
        <li>Designed and deployed Retrieval-Augmented Generation (RAG) and Agentic-RAG pipelines.</li>
        <li>Built multi-agent systems for reasoning, orchestration, and task automation.</li>
        <li>Developed generative models for text, image, and synthetic data generation.</li>
      </ul>
      <p><strong>Models & Systems:</strong></p>
      <span class="badge">LLaMA / LLaMA2</span>
      <span class="badge">Qwen-VL</span>
      <span class="badge">T5</span>
      <span class="badge">GPT-style Models</span>
      <span class="badge">RAG</span>
      <span class="badge">Agentic AI</span>
      <span class="badge">Diffusion Models</span>
      <span class="badge">GANs</span>
      <span class="badge">VAEs</span>
    </div>

  </div>
</section>

<section>
  <h2>Tools & Tech Stack</h2>
  <div class="grid">

    <div class="card">
      <h3>Programming & Core Frameworks</h3>
      <span class="badge">Python</span>
      <span class="badge">PyTorch</span>
      <span class="badge">TensorFlow</span>
      <span class="badge">PyTorch Lightning</span>
      <span class="badge">NumPy</span>
      <span class="badge">OpenCV</span>
    </div>

    <div class="card">
      <h3>Computer Vision</h3>
      <span class="badge">Ultralytics</span>
      <span class="badge">YOLOv5–v8</span>
      <span class="badge">Faster R-CNN</span>
      <span class="badge">RetinaNet</span>
      <span class="badge">U-Net</span>
      <span class="badge">U-Net++</span>
      <span class="badge">DeepLabV3+</span>
      <span class="badge">SAM</span>
      <span class="badge">SAM2</span>
    </div>

    <div class="card">
      <h3>LLMs & Generative AI</h3>
      <span class="badge">LLMs</span>
      <span class="badge">LLM Fine-Tuning</span>
      <span class="badge">LoRA</span>
      <span class="badge">PEFT</span>
      <span class="badge">RAG</span>
      <span class="badge">Agentic RAG</span>
      <span class="badge">Multi-Agent Systems</span>
      <span class="badge">Diffusion Models</span>
      <span class="badge">GANs</span>
      <span class="badge">VAEs</span>
    </div>

    <div class="card">
      <h3>GenAI Tooling & Systems</h3>
      <span class="badge">LangChain</span>
      <span class="badge">LlamaIndex</span>
      <span class="badge">CrewAI</span>
      <span class="badge">FAISS</span>
      <span class="badge">Multimodal Transformers</span>
      <span class="badge">Vision-Language Models</span>
      <span class="badge">Quantization</span>
      <span class="badge">Knowledge Distillation</span>
      <span class="badge">Edge AI</span>
    </div>

  </div>
</section>


<section>
  <h2>Projects</h2>
  <div class="grid">
    <div class="card"><h3>GPT From Scratch</h3><p>Implemented and trained a mini-GPT Transformer from scratch in PyTorch to understand tokenization, attention, and autoregressive generation.</p><a href="https://github.com/RajeshKatta277/GPT_FROM_SCRATCH">GitHub →</a></div>
    <div class="card"><h3>MyTorch Framework</h3><p>Built a PyTorch-like deep learning framework in NumPy, implementing backpropagation, optimizers, and training loops from first principles.</p><a href="https://github.com/RajeshKatta277/MyTorch">GitHub →</a></div>
    <div class="card"><h3>HydraNet (Multi-Task Learning)</h3><p>Single-backbone, multi-head architecture for simultaneous age, gender, and race prediction using joint optimization.</p><a href="https://github.com/RajeshKatta277/HydraNet-Multi-Task-Learning-in-Facial-Attribute-Analysis">GitHub →</a></div>
    <div class="card"><h3>Faster R-CNN From Scratch</h3><p>End-to-end implementation of a two-stage object detector to deeply understand region proposals, anchors, and localization losses.</p><a href="https://github.com/RajeshKatta277/Faster-RCNN_From_Scratch">GitHub →</a></div>
    <div class="card"><h3>Vehicle Detection & Counting</h3><p>Real-time traffic analytics pipeline using YOLOv8 and DeepSORT for detection, tracking, and counting.</p><a href="https://github.com/RajeshKatta277/Vehicle-Detection-and-Counting-using-YOLOV8-and-DeepSort">GitHub →</a></div>
    <div class="card"><h3>AI Multi-Agent Code Reviewer</h3><p>LLM-powered multi-agent system for automated code analysis, reasoning, and review workflows.</p><a href="https://github.com/RajeshKatta277/Code-Reviewer-Advanced-Multi-Agent-System">GitHub →</a></div>
  </div>
</section>

<section>
  <h2>Writing & Blogs</h2>
  <p class="muted">I regularly write long-form technical blogs explaining concepts from first principles, covering Computer Vision, Deep Learning, LLMs, and Generative AI. My writing focuses on intuition, math, and real-world implementation details.</p>
  <div class="grid">
    <div class="card"><h3>The Attention Mechanism: A Deep Dive into How AI Understands Context</h3><p>A concise deep dive into the attention mechanism, explaining how queries, keys, and values enable neural networks to capture context and dependencies in sequences.</p><a href="https://medium.com/@kattarajesh2001/the-attention-mechanism-a-deep-dive-into-how-ai-understands-context-4623b5406ca1">Read →</a></div>
  <div class="card"><h3>Word and Sentence Embeddings</h3><p>Explains how word and sentence embeddings represent language as dense vectors, capturing semantic meaning and relationships that power modern LLMs.</p><a href="https://medium.com/@kattarajesh2001/llms-1-word-and-sentence-embeddings-77371e1eeb0a">Read →</a></div>
  
  <div class="card"><h3>Two-Stage Object Detectors Explained</h3><p>Deep dive into R-CNN, Fast R-CNN, and Faster R-CNN architectures with clear intuition and mathematical grounding.</p><a href="https://medium.com/@kattarajesh2001">Read →</a></div>
  
  
 <div class="card"><h3>Object Detection Part-3: One Stage Detectors: YOLO</h3><p>Breaks down one-stage object detectors like YOLO, explaining how they predict bounding boxes and class probabilities directly and efficiently in a single pass for real-time detection.</p><a href="https://medium.com/@kattarajesh2001/object-detection-part-3-one-stage-detectors-yolo-a4a6b4dd2d33">Read →</a></div>
    
    
    
    
    
    <div class="card"><h3>Object Detection Part -2: Two-Stage Object Detectors Explained</h3><p>Deep dive into Two stage object detection models like R-CNN, Fast R-CNN, and Faster R-CNN architectures with clear intuition and mathematical grounding.</p><a href="https://medium.com/@kattarajesh2001">Read →</a></div>
    <div class="card"><h3>Object Detection Part-1: Introduction to object detection</h3><p>Introduces the fundamentals of object detection, covering what it is, how it differs from related tasks like classification and localization, and why it’s important in computer vision.</p><a href="https://medium.com/@kattarajesh2001/object-detection-part-1-introduction-to-object-detection-321f1fd56295">Read →</a></div>
    <div class="card"><h3>Understanding Neural Networks in depth</h3><p>An introductory guide to neural networks from first principles, explaining how they work and how key components like neurons, activations, and layers come together.</p><a href="https://medium.com/@kattarajesh2001/mytorch-part-1-understanding-neural-networks-28c716be4348">Read →</a></div>
    <div class="card"><h3>Convolutional Neural Networks In Depth</h3><p>An in-depth look at Convolutional Neural Networks, explaining how convolution, pooling, and feature maps enable hierarchical feature learning for image tasks in deep learning.</p><a href="https://medium.com/@kattarajesh2001/convolutional-neural-networks-in-depth-c2fb81ebc2b2">Read →</a></div>
    <div class="card"><h3>WHAT IS MACHINE LEARNING</h3><p>A clear overview of machine learning, explaining how algorithms learn patterns from data to make predictions and decisions without explicit programming.</p><a href="https://medium.com/@kattarajesh2001/what-is-machine-learning-51d1eb17d2fc">Read →</a></div>
  </div>
  <p class="muted" style="margin-top:20px">Read all my blogs on <a href="https://medium.com/@kattarajesh2001">Medium →</a></p>
</section>

<section>
  <h2>Education</h2>
  <div class="timeline">
    <div class="timeline-item">
      <h3>Rajiv Gandhi University Of Knowledge Technologies</h3>
      <p class="muted">2019 – 2023</p>
      <p>
        Bachelor of Technology in Mechanical Engineering with a minor in Mathematics
      </p>
      
    </div>
  </div>
</section>

<section>
  <h2>Professional Experience</h2>
  <div class="timeline">

    <div class="timeline-item">
      <h3>Machine Learning Engineer — Vassar Labs</h3>
      <p class="muted">May 2024 – Present | Hyderabad, India</p>
      <p>
        Working as a core Machine Learning Engineer building <strong>end-to-end, production-grade AI systems</strong>
        across Computer Vision, Generative AI, and Large Language Models. My role spans research, model development,
        system design, optimization, and deployment.
      </p>
      <p>
        Designed and implemented a <strong>multitask AI engine</strong> capable of handling image classification,
        object detection, and semantic segmentation across multiple domains. This engine supports flexible
        experimentation and deployment of architectures such as CNNs, Vision Transformers, Faster R-CNN,
        RetinaNet, YOLO, U-Net, and U-Net++.
      </p>
      <p>
        Fine-tuned <strong>Qwen-3 VL (4B)</strong> on large-scale pest and crop disease datasets using
        <strong>LoRA / PEFT</strong>. Integrated a complete <strong>Retrieval-Augmented Generation (RAG)</strong>
        pipeline to enable intelligent pest and disease monitoring, contextual analysis, and remedy
        recommendation systems.
      </p>
      <p>
        Developed <strong>Generative AI models</strong> including <strong>GANs, Diffusion Models, and VAEs</strong>
        to generate synthetic agricultural imagery, addressing class imbalance and improving model
        generalization in low-data regimes.
      </p>
      <p>
        Implemented <strong>Vision Transformers and U-Net++</strong> for high-resolution building segmentation
        tasks, achieving a <strong>Dice Score improvement of ~9%</strong> over baseline approaches.
      </p>
      <p>
        Designed and built <strong>HydraChat</strong>, a multitask LLM system capable of chatting, summarization,
        translation, and question answering by leveraging <strong>LoRA adapters</strong> on top of
        <strong>T5 and LLaMA2</strong> models.
      </p>
      <p>
        Developed and deployed <strong>RAGGPT</strong>, an enterprise-grade retrieval-augmented chatbot
        integrating <strong>LangChain, FAISS, and LLM-based contextual fusion</strong> for knowledge-driven
        question answering across internal documents.
      </p>
      <p>
        Optimized <strong>RetinaNet and YOLOv8</strong> models for edge deployment using
        <strong>GIoU + Focal Loss</strong>, quantization, and knowledge distillation. Achieved
        <strong>>90% reduction in model size</strong> while retaining strong performance
        (approximately <strong>70% mAP</strong>).
      </p>
      <p>
        Engineered <strong>multimodal Transformer architectures</strong> for vision–language fusion and
        contextual reasoning over satellite imagery, enabling richer semantic understanding for
        geospatial analytics.
      </p>
    </div>

    <div class="timeline-item">
      <h3>Deep Learning Engineer — Mevlana Technologies (Isaac Air – Stealth Mode Product)</h3>
      <p class="muted">Mar 2023 – Apr 2024 | Gurgaon, India</p>
      <p>
        Worked on cutting-edge <strong>autonomous navigation AI systems</strong> by combining computer
        vision and natural language understanding for robotic and aerial platforms.
      </p>
      <p>
        Integrated <strong>Large Language Models</strong> with scene-context understanding pipelines to
        interpret natural language commands and convert them into actionable behaviors for autonomous systems.
      </p>
      <p>
        Implemented <strong>Diffusion Canvas</strong>, a text-to-image generation and editing platform built
        using <strong>Stable Diffusion and ControlNet</strong>, enabling controlled image synthesis and
        prompt-based editing workflows.
      </p>
      <p>
        Designed and developed <strong>VisionGPT</strong>, a multimodal architecture combining
        <strong>CLIP-based visual encoders</strong> with <strong>GPT-2</strong> to perform image captioning
        and visual question answering.
      </p>
    </div>

    <div class="timeline-item">
      <h3>Deep Learning Engineer Intern — Mevlana Technologies (Isaac Air)</h3>
      <p class="muted">Jan 2023 – Mar 2023 | Gurgaon, India</p>
      <p>
        Developed early-stage <strong>NLP and vision–language capabilities</strong> for Isaac’s AI module,
        focusing on multimodal perception and reasoning.
      </p>
      <p>
        Built image-to-text and scene-understanding prototypes using
        <strong>CLIP, Vision Transformers, and GPT-2</strong>, exploring prompt-based interaction
        and multimodal alignment.
      </p>
      <p>
        Implemented multilingual text processing pipelines and experimented with prompt engineering
        techniques for flexible user interaction.
      </p>
    </div>

    <div class="timeline-item">
      <h3>Natural Language Processing Intern — Indian Institute of Information Technology Surat</h3>
      <p class="muted">Jun 2022 – Aug 2022</p>
      <p>
        Developed <strong>sequence-to-sequence machine translation systems</strong> for
        Hindi → English translation.
      </p>
      <p>
        Implemented text normalization pipelines and created a <strong>200-word bilingual mapping</strong>
        to correct misspellings, leveraging <strong>mBART</strong> and the <strong>Google Translate API</strong>.
      </p>
      <p>
        Achieved a <strong>BLEU score of 0.38</strong> on the final machine translation system through
        careful preprocessing, training, and evaluation.
      </p>
    </div>

  </div>
</section>

<section>
  <h2>Contact</h2>
  <p class="muted">Interested in collaboration or opportunities? Drop me a message.</p>
  <form action="https://formspree.io/f/xeeleejq" method="POST">
    <input type="text" name="name" placeholder="Your name" required />
    <input type="email" name="email" placeholder="Your email" required />
    <textarea name="message" rows="5" placeholder="Your message" required></textarea>
    <button type="submit">Send Message</button>
  </form>
</section>

<footer>
  <p>© 2026 Rajesh Katta · AI Engineer</p>
</footer>

</div>
</body>
</html>

